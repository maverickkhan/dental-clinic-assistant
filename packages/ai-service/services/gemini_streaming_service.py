import google.generativeai as genai
from typing import List, AsyncGenerator
from config import settings
from models import ChatHistoryItem


class GeminiStreamingService:
    """Service for streaming responses from Google Gemini API."""

    EMERGENCY_KEYWORDS = [
        "severe pain", "bleeding", "swollen", "emergency", "accident",
        "broken tooth", "knocked out", "unbearable", "can't eat",
        "can't sleep", "infection", "abscess"
    ]

    EMERGENCY_RESPONSE = """⚠️ IMPORTANT: Based on your message, this may require immediate attention. Please contact the clinic directly at your earliest convenience. If this is a dental emergency (severe pain, bleeding, or trauma), please call our emergency line or visit the nearest emergency dental clinic immediately.

For reference, common dental emergencies include:
- Severe, persistent toothache
- Knocked-out tooth
- Broken or chipped tooth with pain
- Severe bleeding that won't stop
- Swelling in the mouth or face
- Abscess or infection

Our clinic staff will be able to provide immediate guidance and schedule an urgent appointment if needed."""

    def __init__(self):
        """Initialize Gemini AI service."""
        genai.configure(api_key=settings.gemini_api_key)
        self.model = genai.GenerativeModel(settings.gemini_model)

    def detect_emergency(self, message: str) -> bool:
        """Detect if message contains emergency keywords."""
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in self.EMERGENCY_KEYWORDS)

    def build_system_prompt(self, patient_name: str, medical_notes: str | None) -> str:
        """Build the system prompt with patient context."""
        truncated_notes = "No medical notes available"
        if medical_notes:
            truncated_notes = medical_notes[:settings.max_medical_notes_length]
            if len(medical_notes) > settings.max_medical_notes_length:
                truncated_notes += "..."

        return f"""You are a knowledgeable and empathetic dental assistant AI helping clinic staff communicate with patients.

IMPORTANT GUIDELINES:
- Provide professional, concise (2-3 paragraphs max), non-technical responses
- Focus on dental procedures, care instructions, and general dental health questions
- Use simple, patient-friendly language
- Be warm, empathetic, and reassuring
- NEVER diagnose medical conditions or prescribe treatments
- NEVER provide specific medical advice - always defer to the dentist
- For emergencies (severe pain, bleeding, trauma), advise immediate contact with clinic or emergency services
- If unsure, recommend scheduling an appointment with the dentist

PATIENT CONTEXT:
- Patient Name: {patient_name}
- Medical Notes: {truncated_notes}

Remember: You are assisting clinic staff in communicating with patients, not replacing professional dental advice."""

    def build_conversation_history(self, chat_history: List[ChatHistoryItem]) -> str:
        """Build conversation history string from chat messages."""
        if not chat_history:
            return ""

        # Get last N messages
        recent_messages = chat_history[-settings.max_chat_history:]

        formatted_messages = []
        for msg in recent_messages:
            role = "User" if msg.role == "user" else "Assistant"
            formatted_messages.append(f"{role}: {msg.content}")

        return "\n\n".join(formatted_messages)

    async def generate_response_stream(
        self,
        message: str,
        patient_name: str,
        medical_notes: str | None,
        chat_history: List[ChatHistoryItem]
    ) -> AsyncGenerator[str, None]:
        """
        Generate AI response as a stream of text chunks.

        Yields:
            Text chunks as they are generated by Gemini
        """
        # Build prompt
        system_prompt = self.build_system_prompt(patient_name, medical_notes)
        conversation_history = self.build_conversation_history(chat_history)

        # Combine all parts
        full_prompt = f"{system_prompt}\n\n{conversation_history}\n\nUser: {message}\n\nAssistant:"

        try:
            # Generate streaming response
            response = await self.model.generate_content_async(
                full_prompt,
                generation_config={
                    "temperature": settings.temperature,
                    "max_output_tokens": settings.max_output_tokens,
                },
                stream=True  # Enable streaming!
            )

            # Yield chunks as they arrive
            async for chunk in response:
                if chunk.text:
                    yield chunk.text

        except Exception as e:
            # Handle API errors
            error_msg = str(e)

            if "quota" in error_msg.lower() or "limit" in error_msg.lower():
                raise Exception("AI service temporarily unavailable due to high demand. Please try again later.")

            if "api key" in error_msg.lower():
                raise Exception("AI service configuration error. Please contact support.")

            raise Exception(f"AI service error: {error_msg}")
